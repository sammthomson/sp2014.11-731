#!/usr/bin/env python
import argparse
from itertools import islice
import sys
import models
import heapq
from collections import namedtuple


Hypothesis = namedtuple('hypothesis', 'logprob, lm_state, predecessor, phrase')


def extract_english_recursive(h):
    """ Follows all back-pointers to recover the full translation """
    return '' if h.predecessor is None else '%s%s ' % (
        extract_english_recursive(h.predecessor), h.phrase.english)


def extract_tm_log_prob(h):
    """ Follows all back-pointers to recover the full log probability of the given hypothesis """
    return 0.0 if h.predecessor is None else h.phrase.logprob + extract_tm_log_prob(h.predecessor)


def decode_sentence(foreign_sentence, translation_model, language_model, stack_size=1, verbose=False):
    """
    The following code implements a DP monotone decoding
    algorithm (one that doesn't permute the target phrases).
    Hence all hypotheses in stacks[i] represent translations of
    the first i words of the input sentence.
    HINT: Generalize this so that stacks[i] contains translations
    of any i words (remember to keep track of which words those
    are, and to estimate future costs)
    """
    stacks = [{} for _ in range(len(foreign_sentence) + 1)]
    stacks[0][language_model.begin()] = Hypothesis(0.0, language_model.begin(), None, None)
    for start, stack in enumerate(stacks[:-1]):
        # extend the top `stack_size` hypotheses in the current stack
        for hypothesis in heapq.nlargest(stack_size, stack.itervalues(), key=lambda h: h.logprob):  # prune
            for end in xrange(start + 1, len(foreign_sentence) + 1):
                foreign_phrase = foreign_sentence[start:end]
                if foreign_phrase in translation_model:
                    for english_phrase in translation_model[foreign_phrase]:
                        log_prob = hypothesis.logprob + english_phrase.logprob
                        lm_state = hypothesis.lm_state
                        for word in english_phrase.english.split():
                            lm_state, word_log_prob = language_model.score(lm_state, word)
                            log_prob += word_log_prob
                        log_prob += language_model.end(lm_state) if end == len(foreign_sentence) else 0.0
                        new_hypothesis = Hypothesis(log_prob, lm_state, hypothesis, english_phrase)
                        # second case is recombination
                        if lm_state not in stacks[end] or stacks[end][lm_state].logprob < log_prob:
                            stacks[end][lm_state] = new_hypothesis

    # find best translation by looking at the best scoring hypothesis
    # on the last stack
    winner = max(stacks[-1].itervalues(), key=lambda h: h.logprob)
    if verbose:
        tm_log_prob = extract_tm_log_prob(winner)
        sys.stderr.write('LM = %f, TM = %f, Total = %f\n' %
                         (winner.logprob - tm_log_prob, tm_log_prob, winner.logprob))
    return extract_english_recursive(winner)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Simple phrase based decoder.')
    parser.add_argument('-i', '--input', dest='input', default='data/input',
                        help='File containing sentences to translate (default=data/input)')
    parser.add_argument('-t', '--translation-model', dest='tm', default='data/tm',
                        help='File containing translation model (default=data/tm)')
    parser.add_argument('-s', '--stack-size', dest='s', default=1, type=int, help='Maximum stack size (default=1)')
    parser.add_argument('-n', '--num_sentences', dest='num_sents', default=sys.maxint, type=int,
                        help='Number of sentences to decode (default=no limit)')
    parser.add_argument('-l', '--language-model', dest='lm', default='data/lm',
                        help='File containing ARPA-format language model (default=data/lm)')
    parser.add_argument('-v', '--verbose', dest='verbose', action='store_true', default=False,
                        help='Verbose mode (default=off)')
    opts = parser.parse_args()

    translation_model = models.TM(opts.tm, sys.maxint)
    language_model = models.LM(opts.lm)
    sys.stderr.write('Decoding %s...\n' % (opts.input,))
    with open(opts.input) as input_file:
        for line in islice(input_file, opts.num_sents):
            foreign_sentence = tuple(line.strip().split())
            print(decode_sentence(foreign_sentence, translation_model, language_model, opts.s, opts.verbose))
